https://blog.csdn.net/weixin_44981707/article/details/115610686
1.使用领域：（用C写的引擎）
	快速的吞吐量的情况


2.特点
	1.Redis 是基于内存操作的，吞吐量非常高，可以在 1s内完成十万次读写操作
	2.Redis 的读写模块是单线程，每个操作都具原子性
	3.Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启可以再次加载，但可能会有极短时间内数据丢失
	4.Redis 支持多种数据结构，String，list，set，zset，hash等



3.数据结构
	1.String
	字符串 string 是 Redis 最简单的数据结构。Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。Redis 的 string 可以包含任何数据，比如 jpg图片或者序列化的对象
	
	内部实现：本质为一个char*
	技巧：1.键值对操作
		 2.批量键值对：批量对多个字符串进行读写，节省时间
		 3.过期和set命令扩展：可以对key设置过期时间，到点自动删除，常用来控制缓存的失效时间
		 4.计数：如果value是一个整数，还可以对其自增，范围为signed long的最大最小值
	2.List
	本质为一个双向链表，当其弹出最后一个元素后，删除该链表Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符
串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。
	3.Hash(字典)
	hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。
	hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。
	有这两种hash：
	1.ziplist：如果hash对象保存的键和值字符串长度都小于64字节且hash对象保存的键值对数量小于512，则采用这种
	数据量较小的时候，把所有的key和value当成一个元素，顺序地存入ziplist中，构成有序
	2.dict（字典）：其他情况采用这种数据结构，本质为一个value只能是string的unordered_map
	
	4.Set
	set 是一个无序的、自动去重的集合数据类型，Set 底层用两种数据结构存储
	intset：如果元素个数少于默认值512且元素可以用整型，则用这种数据结构
	dict（字典）：其他情况采用这种数据结构
	5.zset(有序集合)
	当元素比较少的时候，zset还是使用一个双向链表来存储数据，但是双向链表按照对应的score来进行排序
	当元素很多的时候，redis底层采用了skiplist的做法，也就是hash+skiplist,需要注意的是redis底层采用了指针的模式，所以并不会消耗多余的内存，注意到redis zset的查找时间复杂度为O(logn)这是由于其采用了多层链表的操作（类似二分查找）
	但是多层链表的话，每次插入都需要调整插入位置其后的元素，导致最终的时间复杂度仍旧为O(n),redis避免了这个问题
	具体做法为：每次新插入一个节点，随机生成一个大于等于1的数，代表其层数。



4.过期策略
	Redis 所有的数据结构都可以设置过期时间，时间一到，就会自动删除。
	那么对于过期的key，redis是怎么保证不会因为太多而误删漏删呢？
	1.过期key集合
	redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，它还会使用惰性策略来删除过期的 key，所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，如果过期了就立即删除。定时删除是集中处理，惰性删除是零散处理。
	2.定时扫描策略
	Redis 默认会每秒进行十次过期扫描，过期扫描不会遍历过期字典中所有的 key，而是
	采用了一种简单的贪心策略。
	1.从过期字典中随机 20 个 key；
	2.删除这 20 个 key 中已经过期的 key；
	3.如果过期的 key 比率超过 1/4，那就重复步骤 1；
  	同时，为了保证过期扫描不会出现循环过度，导致线程卡死现象，算法还增加了扫描时间的上限，默认不会超过 25ms。



5.内存淘汰机制
Redis 数据库可以通过配置文件来配置最大缓存，当写入的数据发现没有足够的内存可用的时候，Redis 会触发内存淘汰机制。Redis 为了满足多样化场景，提供了八种策略，可以在 redis.config 文件中配置。
	1.volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
	2.volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰
	3.volatile-random：从已设置过期时间的数据集中任意选择数据淘汰
	4.volatile-lfu：从已设置过期时间的数据集中挑选使用频率最低的数据淘汰
	5.allkeys-lru：从所有数据集中挑选最近最少使用的数据淘汰
	6.allkeys-lfu：从所有数据集中挑选使用频率最低的数据淘汰
	7.allkeys-random：从所有数据集中任意选择数据淘汰
	8.noenviction：不回收任何数据，返回一个写操作的错误信息。这也是默认策略



6.redis持久化
	Redis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。
  	Redis 的持久化机制有两种，第一种是快照，第二种是 AOF 日志。快照是一次全量备份，AOF 日志是连续的增量备份。快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本。AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。
	1.快照原理
	redis为单线程程序，这个线程要负责多个客户端套接字的兵法读写操作和内存数据结构的逻辑读写
	在服务线上请求的同时，Redis 还需要进行内存快照，内存快照要求 Redis 必须进行文件 IO 操作，可文件 IO 操作是不能使用多路复用 API。
	这意味着单线程同时在服务线上的请求还要进行文件 IO 操作，文件 IO 操作会严重拖垮服务器请求的性能。还有个重要的问题是为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变，比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这尼玛要怎么搞？
	Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久化
	持久化的时候调用glibc的函数fork出一个子进程，快照持久化交给子进程处理，父进程继续处理客户端的请求，当父进程修改时，若子进程进行持久化，会发生如下操作：
	操作系统的 COW 机制来进行数据段页面的分离。数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。
	随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的 2 倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。
  子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。
	2.AOF原理
	AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录。
	Redis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令存储到 AOF 日志缓存中，AOF 日志缓存 copy 到 内核缓存，但还没有刷到磁盘，也就是先写日志，然后再执行指令。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。
	Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。
	Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。
	Redis混合持久化
	重启 Redis 时，我们很少使用 rdb 来恢复内存状态，因为会丢失大量数据。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。
  Redis 4.0 为了解决这个问题，带来了一个新的持久化选项——混合持久化。将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。
  于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF 全量文件重放，重启效率因此大幅得到提升。

7.Redis集群
	1.Sentinel
	Redis用来抵抗单点故障的方式
	我们可以将 Redis Sentinel 集群看成是一个 ZooKeeper 集群，它是集群高可用的心脏，它一般是由 3～5 个节点组成，这样挂了个别节点集群还可以正常运转。它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端。如此应用程序将无需重启即可自动完成节点切换。
	2.消息丢失
	Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个参数可以限制主从延迟过大。
	min-slaves-to-write 1

	min-slaves-max-lag 10
	第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写请求，丧失可用性。何为正常复制，何为异常复制？这个就是由第二个参数控制的，它的单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，是谓异常复制。
	3.Cluster
	相对于 Codis 的不同，它是去中心化的，如图所示，该集群有三个 Redis 节点组成，每个节点负责整个集群的一部分数据，每个节点负责的数据多少可能不一样。这三个节点相互连接组成一个对等的集群，它们之间通过一种特殊的二进制协议相互交互集群信息。
	———————————————————————.——————————.———————
	   ⬆️				      ⬆️      ⬆️
	[node1]                  [node2]    [node3]
	Redis Cluster 将所有数据划分为 16384个slots，它比 Codis 的 1024 个槽划分的更为精细，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中，它不像 Codis，它不需要另外的分布式存储来存储节点槽位信息。
	当 Redis Cluster 的客户端来连接集群时，它也会得到一份集群的槽位配置信息。这样当客户端要查找某个 key 时，可以直接定位到目标节点。
	RedisCluster 是直接定位。客户端为了可以直接定位某个具体的 key 所在的节点，它就需要缓存槽位相关信息，这样才可以准确快速地定位到相应的节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。
	RedisCluster 的每个节点会将集群的配置信息持久化到配置文件中，所以必须确保配置文件是可写的，而且尽量不要依靠人工修改配置文件。
	槽位定位算法：
	Cluster 默认会对 key 值使用 crc32 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位。Cluster 还允许用户强制某个 key 挂在特定槽位上，通过在 key 字符串里面嵌入 tag 标记，这就可以强制 key 所挂在的槽位等于 tag 所在的槽位。
	跳转：
	当客户端向一个错误的节点发出了指令，该节点会发现指令的 key 所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。
	槽位迁徙：
	Redis 迁移的单位是槽，Redis 一个槽一个槽进行迁移，当一个槽正在迁移时，这个槽就处于中间过渡状态。这个槽在原节点的状态为 migrating，在目标节点的状态为 importing，表示数据正在从源流向目标。

  	迁移工具：
	redis-trib 首先会在源和目标节点设置好中间过渡状态，然后一次性获取源节点槽位的所有 key 列表(keysinslot 指令，可以部分获取)，再挨个 key 进行迁移。每个 key 的迁移过程是以原节点作为目标节点的「客户端」，原节点对当前的 key 执行 dump 指令得到序列化内容，然后通过「客户端」向目标节点发送指令 restore 携带序列化的内容作为参数，目标节点再进行反序列化就可以将内容恢复到目标节点的内存中，然后返回「客户端」OK，原节点「客户端」收到后再把当前节点的 key 删除掉就完成了单个 key 迁移的整个过程。
	从以上过程可以看出，迁移是会影响服务效率的，同样的指令在正常情况下一个 ttl 就能完成，而在迁移中得 3 个 ttl 才能搞定。
	网络抖动：
	真实世界的机房网络往往并不是风平浪静的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。

  为解决这种问题，Redis Cluster 提供了一种选项 cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。

  还有另外一个选项 cluster-slave-validity-factor 作为倍乘系数来放大这个超时时间来宽松容错的紧急程度。如果这个系数为零，那么主从切换是不会抗拒网络抖动的。如果这个系数大于 1，它就成了主从切换的松弛系数。
	
	可能下线 (PFAIL-Possibly Fail) 与确定下线 (Fail)：
	因为 Redis Cluster 是去中心化的，一个节点认为某个节点失联了并不代表所有的节点都认为它失联了。所以集群还得经过一次协商的过程，只有当大多数节点都认定了某个节点失联了，集群才认为该节点需要进行主从切换来容错。
	Redis 集群节点采用 Gossip 协议来广播自己的状态以及自己对整个集群认知的改变。比如一个节点发现某个节点失联了 (PFail)，它会将这条信息向整个集群广播，其它节点也就可以收到这点失联信息。如果一个节点收到了某个节点失联的数量 (PFail Count) 已经达到了集群的大多数，就可以标记该节点为确定下线状态 (Fail)，然后向整个集群广播，强迫其它节点也接收该节点已经下线的事实，并立即对该失联节点进行主从切换。

8.Redis的事务等
	1.分布式锁
	比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状态这两个操作不是原子的。（Wiki 解释：所谓 原子操作是指不会被线程调度机制打断的操作；这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。）
	分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。占坑一般是使用 setnx(set if not exists) 指令，只允许被一个客户端占坑。先来先占， 用完了，再调用 del 指令释放茅坑。
	> setnx lock_codehole true # setnx 不存在 key 会		添加，存在 不会覆盖
	(integer) 1
	...do something critical...
	> del lock_codehole 
	(integer) 1
	
	2.锁的释放
	但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用， 这样就会陷入死锁，锁永远得不到释放。
	于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也可以保证 5 秒之后锁会自动释放。
	3.锁的超时
	Redis 的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制， 就会出现问题。 因为这时候锁过期了， 第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了。这样就会陷入无限循环中。
	原理：redisson 内部提供了一个监控锁的看门狗，可以设置 lockWatchdogTimeout（监控锁的看门狗超时时间，默认是 30s），在监控锁被主动关闭前，会不断的延长监控锁的有效期，如果 redisson 客户端节点（也就是我们的服务器）宕机，那么监控锁时间到后自动关闭。


9.缓存的问题
	1.缓存处理流程
	前台请求，后台先从缓存中取数据，取到直接返回结果，取不到时从数据库中取，数据库取到更新缓存，并返回结果，数据库也没取到，那直接返回空结果。
	2.缓存穿透
	缓存穿透是指缓存和数据库中都没有的数据，而用户不断发起请求，如发起为id为“-1”的数据或id为特别大不存在的数据。这时的用户很可能是攻击者，攻击会导致数据库压力过大。
	解决：
		1.接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
		2.从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
	3.缓存击穿
	缓存击穿是指缓存中没有但数据库中有的单条数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力
		1.设置热点数据永远不过期。
		2.加互斥锁。读数据库时需要获取锁，一条请求拿到锁之后读取数据并更新缓存，为了防止那些抢锁失败线程重新获取到锁后又进行读数据库操作，这里采用双重检验锁方式。
	4.缓存雪崩
	缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大，引起数据库压力过大甚至 down机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。
		1.缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
		2.设置热点数据永远不过期。
